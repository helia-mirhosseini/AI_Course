{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07985bf7",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;       /* Dark Blue-Grey Background */\n",
    "        color: #cdd6f4;                  /* Soft White Text */\n",
    "        border-left: 6px solid #89b4fa;  /* Blue Accent Border */\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    \n",
    "    /* Header style */\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;                  /* Blue Header */\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "\n",
    "    /* Important keywords */\n",
    "    .note-box strong {\n",
    "        color: #f9e2af;                  /* Soft Gold/Yellow */\n",
    "        font-weight: 600;\n",
    "    }\n",
    "\n",
    "    /* Inline code snippets */\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;                  /* Soft Red/Pink */\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "\n",
    "    /* Lists */\n",
    "    .note-box ul {\n",
    "        padding-left: 20px;\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    .note-box li {\n",
    "        margin-bottom: 8px;\n",
    "    }\n",
    "</style>\n",
    "<div class=\"note-box\">\n",
    "    <h2>Chapter 4.4: The Creative Machine (Text Generation)</h2>\n",
    "    <p>\n",
    "        <strong>Objective</strong>: In Chapter 4.3, we classified existing text (Many-to-One). Now, we will make the model <strong>generate</strong> new text (Many-to-Many). We will build a Character-Level RNN that learns to write like Shakespeare.\n",
    "    </p>\n",
    "    <p><strong>The Math of Generation (Autoregression)</strong>:</p>\n",
    "    <p>We model the probability of the next character  <i>x<sub>t+1</sub></i> given the current character <i>x<sub>t</sub></i> and the hidden state <i>h<sub>t</sub></i> (memory of the past):</p>\n",
    "\n",
    "$$ P(x_{t+1} | x_t, h_t) = \\text{Softmax}(W \\cdot h_t + b) $$\n",
    "<p><strong>Key Concepts</strong>:</p>\n",
    "    <ul>\n",
    "        <li><strong>Character-Level Modeling</strong>: Instead of a vocabulary of 50,000 words, we use ~65 characters (the alphabet). This is computationally cheaper for learning concepts.</li>\n",
    "        <li><strong>Teacher Forcing</strong>: During training, we feed the <em>correct</em> next character as input for the next step, regardless of what the model predicted.</li>\n",
    "        <li><strong>Temperature Sampling</strong>: A mathematical trick to control \"creativity\" by scaling the logits before Softmax.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a9d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Check for acceleration\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84065441",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;       /* Dark Blue-Grey Background */\n",
    "        color: #cdd6f4;                  /* Soft White Text */\n",
    "        border-left: 6px solid #89b4fa;  /* Blue Accent Border */\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    \n",
    "    /* Header style */\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;                  /* Blue Header */\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "\n",
    "    /* Important keywords */\n",
    "    .note-box strong {\n",
    "        color: #f9e2af;                  /* Soft Gold/Yellow */\n",
    "        font-weight: 600;\n",
    "    }\n",
    "\n",
    "    /* Inline code snippets */\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;                  /* Soft Red/Pink */\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "\n",
    "    /* Lists */\n",
    "    .note-box ul {\n",
    "        padding-left: 20px;\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    .note-box li {\n",
    "        margin-bottom: 8px;\n",
    "    }\n",
    "</style>\n",
    "<div class=\"note-box\">\n",
    "    <h2>Step 1: The Dataset (Tiny Shakespeare)</h2>\n",
    "    <p>To train a language model, we simply take a sequence of text and offset it by one.</p>\n",
    "    <ul>\n",
    "        <li><strong>Input</strong>: \"Hell\" (indices 0, 1, 2, 3)</li>\n",
    "        <li><strong>Target</strong>: \"ello\" (indices 1, 2, 3, 4)</li>\n",
    "    </ul>\n",
    "    <p>This means for the input 'H', the correct label is 'e'. For input 'e', the label is 'l', and so on.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a0b082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters in text: 353\n",
      "Unique Vocabulary Size: 34\n",
      "Sample Mapping: [('\\n', 0), (' ', 1), (\"'\", 2), (',', 3), ('-', 4)]\n",
      "Input Shape: torch.Size([16, 30])\n",
      "Input Example: ['t', 'e', 'd', ' ', 't']\n",
      "Target Example: ['e', 'd', ' ', 't', 'o']\n"
     ]
    }
   ],
   "source": [
    "# A tiny snippet of Shakespeare for training\n",
    "# (In a real scenario, this would be a much larger text file)\n",
    "text_data = \"\"\"\n",
    "From fairest creatures we desire increase,\n",
    "That thereby beauty's rose might never die,\n",
    "But as the riper should by time decease,\n",
    "His tender heir might bear his memory:\n",
    "But thou, contracted to thine own bright eyes,\n",
    "Feed'st thy light's flame with self-substantial fuel,\n",
    "Making a famine where abundance lies,\n",
    "Thyself thy foe, to thy sweet self too cruel.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Create Character Vocabulary\n",
    "chars = sorted(list(set(text_data)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# 2. Mappings (Character to Integer and vice versa)\n",
    "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "print(f\"Total Characters in text: {len(text_data)}\")\n",
    "print(f\"Unique Vocabulary Size: {vocab_size}\")\n",
    "print(f\"Sample Mapping: {list(char_to_ix.items())[:5]}\")\n",
    "\n",
    "# 3. Custom Dataset Class\n",
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, text, char_to_ix, seq_length=20):\n",
    "        self.text = text\n",
    "        self.char_to_ix = char_to_ix\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        # We can extract (Length - Window_Size) sequences\n",
    "        return len(self.text) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Grab a chunk of text\n",
    "        chunk = self.text[idx : idx + self.seq_length + 1]\n",
    "        \n",
    "        # Convert to integers\n",
    "        encoded = [self.char_to_ix[c] for c in chunk]\n",
    "        \n",
    "        # Input: 0 to End-1 (e.g., \"Hell\")\n",
    "        # Target: 1 to End   (e.g., \"ello\")\n",
    "        input_seq = torch.tensor(encoded[:-1], dtype=torch.long)\n",
    "        target_seq = torch.tensor(encoded[1:], dtype=torch.long)\n",
    "        \n",
    "        return input_seq, target_seq\n",
    "\n",
    "# Hyperparameters\n",
    "SEQ_LEN = 30\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "dataset = ShakespeareDataset(text_data, char_to_ix, SEQ_LEN)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "# Sanity Check\n",
    "x_batch, y_batch = next(iter(dataloader))\n",
    "print(f\"Input Shape: {x_batch.shape}\") # [Batch, Seq_Len]\n",
    "print(f\"Input Example: {[ix_to_char[i.item()] for i in x_batch[0][:5]]}\")\n",
    "print(f\"Target Example: {[ix_to_char[i.item()] for i in y_batch[0][:5]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13129210",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;       /* Dark Blue-Grey Background */\n",
    "        color: #cdd6f4;                  /* Soft White Text */\n",
    "        border-left: 6px solid #89b4fa;  /* Blue Accent Border */\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    \n",
    "    /* Header style */\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;                  /* Blue Header */\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "\n",
    "    /* Important keywords */\n",
    "    .note-box strong {\n",
    "        color: #f9e2af;                  /* Soft Gold/Yellow */\n",
    "        font-weight: 600;\n",
    "    }\n",
    "\n",
    "    /* Inline code snippets */\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;                  /* Soft Red/Pink */\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "\n",
    "    /* Lists */\n",
    "    .note-box ul {\n",
    "        padding-left: 20px;\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    .note-box li {\n",
    "        margin-bottom: 8px;\n",
    "    }\n",
    "</style>\n",
    "<div class=\"note-box\">\n",
    "    <h2>Step 2: The GRU Model</h2>\n",
    "    <p>We use a <strong>GRU (Gated Recurrent Unit)</strong>. It is similar to an LSTM but uses fewer gates (Update and Reset), making it faster.</p>\n",
    "    <p><strong>Architecture Details</strong>:</p>\n",
    "    <ol>\n",
    "        <li><strong>Embedding</strong>: Maps integer IDs to vectors ($E \\in \\mathbb{R}^{V \\times D}$).</li>\n",
    "        <li><strong>GRU Layer</strong>: Processes the sequence. Returns <em>Output</em> (features for every step) and <em>Hidden</em> (final memory state).</li>\n",
    "        <li><strong>Linear Head</strong>: Projects the GRU features back to vocabulary size to predict the next character logits.</li>\n",
    "    </ol>\n",
    "    <p>Unlike text classification where we only used the <em>last</em> hidden state, here we use the output from <strong>every time step</strong> because we make a prediction for every character.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08fa0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextGenerator(\n",
      "  (embedding): Embedding(34, 32)\n",
      "  (gru): GRU(32, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=34, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class TextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        # 1. Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # 2. GRU Layer\n",
    "        # batch_first=True ensures input shape is (Batch, Seq, Feature)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # 3. Output Layer\n",
    "        # Transforms hidden features into probabilities for the next char\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        # x shape: [batch, seq_len]\n",
    "        \n",
    "        embeds = self.embedding(x) # [batch, seq_len, embed_dim]\n",
    "        \n",
    "        # Run RNN\n",
    "        # If 'hidden' is None, PyTorch automatically initializes it to 0s\n",
    "        output, hidden = self.gru(embeds, hidden)\n",
    "        \n",
    "        # output shape: [batch, seq_len, hidden_dim]\n",
    "        \n",
    "        # Predict the next character for every step in the sequence\n",
    "        prediction = self.fc(output) # [batch, seq_len, vocab_size]\n",
    "        \n",
    "        return prediction, hidden\n",
    "\n",
    "# Model Config\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "model = TextGenerator(vocab_size, EMBED_DIM, HIDDEN_DIM).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e730b",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;       /* Dark Blue-Grey Background */\n",
    "        color: #cdd6f4;                  /* Soft White Text */\n",
    "        border-left: 6px solid #89b4fa;  /* Blue Accent Border */\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    \n",
    "    /* Header style */\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;                  /* Blue Header */\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "\n",
    "    /* Important keywords */\n",
    "    .note-box strong {\n",
    "        color: #f9e2af;                  /* Soft Gold/Yellow */\n",
    "        font-weight: 600;\n",
    "    }\n",
    "\n",
    "    /* Inline code snippets */\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;                  /* Soft Red/Pink */\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "\n",
    "    /* Lists */\n",
    "    .note-box ul {\n",
    "        padding-left: 20px;\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    .note-box li {\n",
    "        margin-bottom: 8px;\n",
    "    }\n",
    "</style>\n",
    "<div class=\"note-box\">\n",
    "    <h2>Step 3: Training</h2>\n",
    "    <p>We use <strong>CrossEntropyLoss</strong>. There is a small shape mismatch we need to handle:</p>\n",
    "    <ul>\n",
    "        <li>Model Output: <span class=\\\"code-inline\\\">[Batch, Seq_Len, Vocab_Size]</span></li>\n",
    "        <li>Target: <span class=\\\"code-inline\\\">[Batch, Seq_Len]</span></li>\n",
    "    </ul>\n",
    "    <p>PyTorch's CrossEntropyLoss expects 2D inputs <span class=\\\"code-inline\\\">(N, Classes)</span>. So, we must <strong>flatten</strong> the Batch and Sequence dimensions together before calculating loss.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147d058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training ---\n",
      "Epoch 10/100 | Loss: 0.1297\n",
      "Epoch 20/100 | Loss: 0.1137\n",
      "Epoch 30/100 | Loss: 0.1066\n",
      "Epoch 40/100 | Loss: 0.1061\n",
      "Epoch 50/100 | Loss: 0.1032\n",
      "Epoch 60/100 | Loss: 0.1027\n",
      "Epoch 70/100 | Loss: 0.1013\n",
      "Epoch 80/100 | Loss: 0.1011\n",
      "Epoch 90/100 | Loss: 0.1017\n",
      "Epoch 100/100 | Loss: 0.1005\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "print(\"--- Starting Training ---\")\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        # We ignore hidden state here (stateless training between batches)\n",
    "        predictions, _ = model(x) \n",
    "        \n",
    "        # Reshape for Loss\n",
    "        # Flattening Batch and Sequence length into one long dimension\n",
    "        # Preds: [Batch*Seq, Vocab], Targets: [Batch*Seq]\n",
    "        loss = criterion(predictions.reshape(-1, vocab_size), y.reshape(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767af92",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;       /* Dark Blue-Grey Background */\n",
    "        color: #cdd6f4;                  /* Soft White Text */\n",
    "        border-left: 6px solid #89b4fa;  /* Blue Accent Border */\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    \n",
    "    /* Header style */\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;                  /* Blue Header */\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "\n",
    "    /* Important keywords */\n",
    "    .note-box strong {\n",
    "        color: #f9e2af;                  /* Soft Gold/Yellow */\n",
    "        font-weight: 600;\n",
    "    }\n",
    "\n",
    "    /* Inline code snippets */\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;                  /* Soft Red/Pink */\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "\n",
    "    /* Lists */\n",
    "    .note-box ul {\n",
    "        padding-left: 20px;\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    .note-box li {\n",
    "        margin-bottom: 8px;\n",
    "    }\n",
    "</style>\n",
    "<div class=\"note-box\">\n",
    "    <h2>Step 4: Generation with Temperature</h2>\n",
    "    <p>During generation, we feed the model's own output back as input for the next step. To prevent the model from getting stuck in loops (e.g., \"the the the\"), we use <strong>Temperature Sampling</strong>.</p>\n",
    "    <p>The math involves dividing the logits ($z$) by a temperature $T$ before the Softmax:</p>\n",
    "\n",
    "$$ P_i = \\frac{e^{z_i / T}}{\\sum e^{z_j / T}} $$\n",
    "\n",
    "<ul>\n",
    "        <li><strong>High T (> 1.0)</strong>: Flattens the distribution. Low probability characters get boosted. <em>Result: Random, creative, prone to typos.</em></li>\n",
    "        <li><strong>Low T (< 1.0)</strong>: Sharpens the distribution. High probability characters get boosted. <em>Result: Conservative, repetitive, safe.</em></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5adc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed 'But ':\n",
      "\n",
      "--- Temp 0.5 ---\n",
      "But thou, contracted to thine own bright eyes,\n",
      "Feed'st thy light's flame with self-substantial fuel,\n",
      "Making a famine where abundance lies,\n",
      "Thyself thy foe, to thy sweet self too cruel.\n",
      "Making a famine whe\n",
      "\n",
      "--- Temp 1.2 ---\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his memory:\n",
      "But thou, contracted to thine own bright eyes,\n",
      "Feed'st thy light's flame with self-substantial fuel,\n",
      "Making a famine where a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(start_str, length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Initialize with start string\n",
    "    input_idxs = [char_to_ix.get(c, 0) for c in start_str]\n",
    "    input_tensor = torch.tensor(input_idxs).unsqueeze(0).to(device) # [1, seq_len]\n",
    "    \n",
    "    # We maintain the hidden state throughout generation\n",
    "    hidden = None\n",
    "    generated_text = start_str\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 2. Process the seed text to build up 'context' (memory)\n",
    "        # We pass the whole sequence, but we only care about the FINAL hidden state\n",
    "        output, hidden = model(input_tensor, hidden)\n",
    "        \n",
    "        # Take the logits for the very last character in the sequence\n",
    "        last_logits = output[:, -1, :]\n",
    "        \n",
    "        for _ in range(length):\n",
    "            # 3. Apply Temperature\n",
    "            # Divide logits by temp. \n",
    "            # If temp is small, big numbers get bigger (peaks sharper).\n",
    "            logits = last_logits / temperature\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            # 4. Sample from the distribution (Weighted Random)\n",
    "            # We don't use argmax, or it would be deterministic\n",
    "            next_char_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = ix_to_char[next_char_idx]\n",
    "            \n",
    "            generated_text += next_char\n",
    "            \n",
    "            # 5. Prepare next input\n",
    "            # The predicted char becomes the input for the next step\n",
    "            input_tensor = torch.tensor([[next_char_idx]]).to(device)\n",
    "            \n",
    "            # Pass new input + OLD hidden state\n",
    "            output, hidden = model(input_tensor, hidden)\n",
    "            last_logits = output[:, -1, :]\n",
    "            \n",
    "    print(f\"--- Temp {temperature} ---\\n{generated_text}\\n\")\n",
    "\n",
    "# Test\n",
    "print(\"Generating from seed 'But ':\\n\")\n",
    "generate_text(\"But \", length=200, temperature=0.5) # Safe\n",
    "generate_text(\"But \", length=200, temperature=1.2) # Chaotic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
