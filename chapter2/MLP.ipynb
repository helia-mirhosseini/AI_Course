{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a67d8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed :int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # If CUDA is present (not your case on Apple M4), this also seeds GPU randomness\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # MPS determinism is not guaranteed across all operations,\n",
    "    # but seeding still helps make runs more stable and comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c00d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        return torch.device(\"mps\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    \n",
    "    return torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9cfa11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int = 28*28,\n",
    "        hidden_dims=(512, 256),\n",
    "        out_dim: int = 10,\n",
    "        activation: str = \"relu\",\n",
    "        use_batchnorm: bool = True,\n",
    "        dropout_p: float = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        def make_activation(name: str) -> nn.Module:\n",
    "            name = name.lower()\n",
    "            if name == \"relu\":\n",
    "                return nn.ReLU()\n",
    "            if name == \"tanh\":\n",
    "                return nn.Tanh()\n",
    "            if name == \"sigmoid\":\n",
    "                return nn.Sigmoid()\n",
    "            raise ValueError(f\"Unknown activation: {name}\")\n",
    "\n",
    "        layers = [nn.Flatten()]  # <-- THIS fixes the 28x28 vs 784 mismatch\n",
    "\n",
    "        prev = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            if use_batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(make_activation(activation))\n",
    "            if dropout_p > 0.0:\n",
    "                layers.append(nn.Dropout(dropout_p))\n",
    "            prev = h\n",
    "\n",
    "        layers.append(nn.Linear(prev, out_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5272f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_classification(model,loader, device):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Fashion-MNIST images are [batch, 1, 28, 28]\n",
    "        # MLP needs vectors [batch, 784]\n",
    "        x = x.view(x.size(), -1)\n",
    "        logits = model(x)  # logits shape: [batch, 10]\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "        total_samples += x.size(0)\n",
    "\n",
    "    return total_loss / total_samples, total_correct / total_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26411a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classification(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    optimizer_name=\"adam\",\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,   # L2 regularization via optimizer\n",
    "    l1_lambda=0.0,       # optional L1 (manual addition to loss)\n",
    "    epochs=10,\n",
    "    grad_clip=None,      # optional: e.g., 1.0\n",
    "):\n",
    "    model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Choose optimizer family (one of your required topics)\n",
    "    optimizer_cls = {\n",
    "        \"sgd\": torch.optim.SGD,\n",
    "        \"rmsprop\": torch.optim.RMSprop,\n",
    "        \"adam\": torch.optim.Adam,\n",
    "    }[optimizer_name]\n",
    "\n",
    "    # weight_decay in PyTorch optimizers implements L2 regularization (weight decay).\n",
    "    # For SGD we usually add momentum to improve convergence.\n",
    "    if optimizer_name == \"sgd\":\n",
    "        optimizer = optimizer_cls(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            momentum=0.9,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optimizer_cls(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # model.train() enables dropout and makes BatchNorm use batch statistics\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Flatten images for MLP\n",
    "            x = x.view(x.size(0), -1)\n",
    "\n",
    "            # Zero old gradients. set_to_none=True can be a bit faster and uses less memory.\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(x)\n",
    "\n",
    "            # Cross-entropy loss (classification)\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            # Optional L1 regularization:\n",
    "            # Adds lambda * sum(|W|) to the loss.\n",
    "            # This encourages sparsity (many weights close to zero).\n",
    "            if l1_lambda > 0.0:\n",
    "                l1 = 0.0\n",
    "                for p in model.parameters():\n",
    "                    # Usually you apply L1 to weight matrices (dim >= 2), not biases\n",
    "                    if p.dim() >= 2:\n",
    "                        l1 = l1 + p.abs().sum()\n",
    "                loss = loss + l1_lambda * l1\n",
    "\n",
    "            # Backpropagation:\n",
    "            # Autograd computes gradients of loss w.r.t. every parameter.\n",
    "            loss.backward()\n",
    "\n",
    "            # Optional gradient clipping:\n",
    "            # If training becomes unstable (exploding gradients), clip norms.\n",
    "            if grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            # Update parameters according to chosen optimizer (SGD/RMSprop/Adam)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track training stats\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            running_correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "            total_samples += x.size(0)\n",
    "\n",
    "        train_loss = running_loss / total_samples\n",
    "        train_acc = running_correct / total_samples\n",
    "\n",
    "        val_loss, val_acc = evaluate_classification(model, val_loader, device)\n",
    "\n",
    "        print(\n",
    "            f\"epoch {epoch:02d} | \"\n",
    "            f\"train_loss={train_loss:.4f} train_acc={train_acc:.4f} | \"\n",
    "            f\"val_loss={val_loss:.4f} val_acc={val_acc:.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087db349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_loaders(batch_size=128, val_ratio=0.1, seed=42):\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Transform pipeline:\n",
    "    # ToTensor: converts PIL image (0..255) -> float tensor (0..1) shaped [1, 28, 28]\n",
    "    # Normalize: centers/scales values to help optimization\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.FashionMNIST(\n",
    "        root=\"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    n_val = int(len(dataset) * val_ratio)\n",
    "    n_train = len(dataset) - n_val\n",
    "\n",
    "    # random_split uses a generator so we can make the split reproducible\n",
    "    train_ds, val_ds = random_split(\n",
    "        dataset,\n",
    "        [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    # On macOS, DataLoader multiprocessing (num_workers>0) can sometimes be slower or problematic\n",
    "    # depending on your environment. num_workers=0 is the most compatible.\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3421aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "epoch 01 | train_loss=0.4936 train_acc=0.8242 | val_loss=0.4007 val_acc=0.8548\n",
      "epoch 02 | train_loss=0.3788 train_acc=0.8604 | val_loss=0.3587 val_acc=0.8717\n",
      "epoch 03 | train_loss=0.3437 train_acc=0.8737 | val_loss=0.3432 val_acc=0.8737\n",
      "epoch 04 | train_loss=0.3231 train_acc=0.8795 | val_loss=0.3361 val_acc=0.8765\n",
      "epoch 05 | train_loss=0.3106 train_acc=0.8847 | val_loss=0.3219 val_acc=0.8818\n",
      "epoch 06 | train_loss=0.2993 train_acc=0.8879 | val_loss=0.3150 val_acc=0.8847\n",
      "epoch 07 | train_loss=0.2874 train_acc=0.8926 | val_loss=0.3148 val_acc=0.8838\n",
      "epoch 08 | train_loss=0.2806 train_acc=0.8956 | val_loss=0.3087 val_acc=0.8898\n",
      "epoch 09 | train_loss=0.2727 train_acc=0.8993 | val_loss=0.3266 val_acc=0.8838\n",
      "epoch 10 | train_loss=0.2671 train_acc=0.8995 | val_loss=0.2976 val_acc=0.8912\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    device = get_device()\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    train_loader, val_loader = get_fashion_mnist_loaders(batch_size=128, val_ratio=0.1, seed=42)\n",
    "\n",
    "    # MLP configuration:\n",
    "    # Change these knobs one at a time to learn each topic.\n",
    "    model = MLP(\n",
    "        in_dim=28 * 28,\n",
    "        hidden_dims=(512, 256),\n",
    "        out_dim=10,\n",
    "        activation=\"relu\",      # try: \"tanh\", \"sigmoid\"\n",
    "        use_batchnorm=True,     # try: False\n",
    "        dropout_p=0.3,          # try: 0.0, 0.1, 0.5\n",
    "    )\n",
    "\n",
    "    train_classification(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        optimizer_name=\"adam\",  # try: \"sgd\", \"rmsprop\", \"adam\"\n",
    "        lr=1e-3,                # tune per optimizer\n",
    "        weight_decay=1e-4,      # L2 regularization\n",
    "        l1_lambda=0.0,          # optional L1, e.g. 1e-7 or 1e-6 (start tiny)\n",
    "        epochs=10,\n",
    "        grad_clip=None,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92b95b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        hidden_dims=(128, 64),\n",
    "        activation: str = \"relu\",\n",
    "        use_batchnorm: bool = True,\n",
    "        dropout_p: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        act_layer = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"tanh\": nn.Tanh,\n",
    "            \"sigmoid\": nn.Sigmoid,\n",
    "        }[activation]\n",
    "\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            if use_batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(act_layer())\n",
    "            if dropout_p > 0.0:\n",
    "                layers.append(nn.Dropout(dropout_p))\n",
    "            prev = h\n",
    "\n",
    "        # Regression output: a single continuous value\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # shape [batch, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2741cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def rmse(pred, target):\n",
    "    return torch.sqrt(torch.mean((pred - target) ** 2)).item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def mae(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target)).item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93dbb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_regression(model, loader, device):\n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_n = 0\n",
    "\n",
    "    # For metrics\n",
    "    preds_all = []\n",
    "    targets_all = []\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        total_n += xb.size(0)\n",
    "\n",
    "        preds_all.append(pred)\n",
    "        targets_all.append(yb)\n",
    "\n",
    "    preds_all = torch.cat(preds_all, dim=0)\n",
    "    targets_all = torch.cat(targets_all, dim=0)\n",
    "\n",
    "    return (total_loss / total_n), rmse(preds_all, targets_all), mae(preds_all, targets_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f66514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_regression(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    optimizer_name=\"adam\",\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,   # L2 regularization\n",
    "    l1_lambda=0.0,       # optional L1\n",
    "    epochs=50,\n",
    "    grad_clip=None\n",
    "):\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    optimizer_cls = {\n",
    "        \"sgd\": torch.optim.SGD,\n",
    "        \"rmsprop\": torch.optim.RMSprop,\n",
    "        \"adam\": torch.optim.Adam,\n",
    "    }[optimizer_name]\n",
    "\n",
    "    if optimizer_name == \"sgd\":\n",
    "        optimizer = optimizer_cls(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            momentum=0.9,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optimizer_cls(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_n = 0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            # Optional L1 regularization\n",
    "            if l1_lambda > 0.0:\n",
    "                l1 = 0.0\n",
    "                for p in model.parameters():\n",
    "                    if p.dim() >= 2:\n",
    "                        l1 = l1 + p.abs().sum()\n",
    "                loss = loss + l1_lambda * l1\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Optional gradient clipping\n",
    "            if grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            total_n += xb.size(0)\n",
    "\n",
    "        train_mse = running_loss / total_n\n",
    "        val_mse, val_rmse, val_mae = evaluate_regression(model, val_loader, device)\n",
    "\n",
    "        print(\n",
    "            f\"epoch {epoch:03d} | \"\n",
    "            f\"train_mse={train_mse:.5f} | \"\n",
    "            f\"val_mse={val_mse:.5f} val_rmse={val_rmse:.5f} val_mae={val_mae:.5f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e636bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_california_housing_loaders(batch_size=128, val_ratio=0.2, seed=42):\n",
    "    # 1) Load data (X: features, y: target)\n",
    "    data = fetch_california_housing()\n",
    "    X = data.data\n",
    "    y = data.target.reshape(-1, 1)  # shape [N, 1]\n",
    "\n",
    "    # 2) Train/val split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y,\n",
    "        test_size=val_ratio,\n",
    "        random_state=seed,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # 3) Standardize features using ONLY the training statistics\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    # 4) Convert to torch tensors (float32 is standard)\n",
    "    X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_t = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "    # 5) TensorDataset + DataLoader\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    val_ds = TensorDataset(X_val_t, y_val_t)\n",
    "\n",
    "    # On macOS: num_workers=0 is most compatible\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_loader, val_loader, X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5b36360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "epoch 001 | train_mse=4.55459 | val_mse=3.61438 val_rmse=1.90115 val_mae=1.75046\n",
      "epoch 002 | train_mse=3.10202 | val_mse=2.15097 val_rmse=1.46662 val_mae=1.26562\n",
      "epoch 003 | train_mse=1.87413 | val_mse=1.05130 val_rmse=1.02533 val_mae=0.79759\n",
      "epoch 004 | train_mse=1.14297 | val_mse=0.67626 val_rmse=0.82235 val_mae=0.61206\n",
      "epoch 005 | train_mse=0.82561 | val_mse=0.51963 val_rmse=0.72085 val_mae=0.52879\n",
      "epoch 006 | train_mse=0.70214 | val_mse=0.48182 val_rmse=0.69413 val_mae=0.51605\n",
      "epoch 007 | train_mse=0.63389 | val_mse=0.46443 val_rmse=0.68149 val_mae=0.50169\n",
      "epoch 008 | train_mse=0.59966 | val_mse=0.42112 val_rmse=0.64894 val_mae=0.46240\n",
      "epoch 009 | train_mse=0.56448 | val_mse=0.41030 val_rmse=0.64054 val_mae=0.46063\n",
      "epoch 010 | train_mse=0.54817 | val_mse=0.40634 val_rmse=0.63745 val_mae=0.45413\n",
      "epoch 011 | train_mse=0.54150 | val_mse=0.41062 val_rmse=0.64080 val_mae=0.46121\n",
      "epoch 012 | train_mse=0.52444 | val_mse=0.41419 val_rmse=0.64358 val_mae=0.46928\n",
      "epoch 013 | train_mse=0.51542 | val_mse=0.38908 val_rmse=0.62377 val_mae=0.44551\n",
      "epoch 014 | train_mse=0.51103 | val_mse=0.42156 val_rmse=0.64928 val_mae=0.48486\n",
      "epoch 015 | train_mse=0.49157 | val_mse=0.39337 val_rmse=0.62719 val_mae=0.45537\n",
      "epoch 016 | train_mse=0.49262 | val_mse=0.38358 val_rmse=0.61933 val_mae=0.44539\n",
      "epoch 017 | train_mse=0.48749 | val_mse=0.40284 val_rmse=0.63470 val_mae=0.45812\n",
      "epoch 018 | train_mse=0.47398 | val_mse=0.38165 val_rmse=0.61777 val_mae=0.44617\n",
      "epoch 019 | train_mse=0.47538 | val_mse=0.36881 val_rmse=0.60730 val_mae=0.43134\n",
      "epoch 020 | train_mse=0.46450 | val_mse=0.47293 val_rmse=0.68770 val_mae=0.53597\n",
      "epoch 021 | train_mse=0.46893 | val_mse=0.36588 val_rmse=0.60488 val_mae=0.42783\n",
      "epoch 022 | train_mse=0.45704 | val_mse=0.37632 val_rmse=0.61345 val_mae=0.43755\n",
      "epoch 023 | train_mse=0.45213 | val_mse=0.37153 val_rmse=0.60953 val_mae=0.43531\n",
      "epoch 024 | train_mse=0.45174 | val_mse=0.43035 val_rmse=0.65601 val_mae=0.48726\n",
      "epoch 025 | train_mse=0.44440 | val_mse=0.39654 val_rmse=0.62972 val_mae=0.45108\n",
      "epoch 026 | train_mse=0.43568 | val_mse=0.40551 val_rmse=0.63679 val_mae=0.45785\n",
      "epoch 027 | train_mse=0.43869 | val_mse=0.38015 val_rmse=0.61656 val_mae=0.43707\n",
      "epoch 028 | train_mse=0.43159 | val_mse=0.48499 val_rmse=0.69641 val_mae=0.53179\n",
      "epoch 029 | train_mse=0.42735 | val_mse=0.42198 val_rmse=0.64960 val_mae=0.47771\n",
      "epoch 030 | train_mse=0.42987 | val_mse=0.36215 val_rmse=0.60179 val_mae=0.41695\n",
      "epoch 031 | train_mse=0.41471 | val_mse=0.44072 val_rmse=0.66387 val_mae=0.49045\n",
      "epoch 032 | train_mse=0.41790 | val_mse=0.36193 val_rmse=0.60161 val_mae=0.42246\n",
      "epoch 033 | train_mse=0.41211 | val_mse=0.40110 val_rmse=0.63333 val_mae=0.44669\n",
      "epoch 034 | train_mse=0.40773 | val_mse=0.40876 val_rmse=0.63935 val_mae=0.44806\n",
      "epoch 035 | train_mse=0.40686 | val_mse=0.39979 val_rmse=0.63229 val_mae=0.44675\n",
      "epoch 036 | train_mse=0.40255 | val_mse=0.36918 val_rmse=0.60760 val_mae=0.43208\n",
      "epoch 037 | train_mse=0.39889 | val_mse=0.49820 val_rmse=0.70584 val_mae=0.53228\n",
      "epoch 038 | train_mse=0.40161 | val_mse=0.43946 val_rmse=0.66292 val_mae=0.47971\n",
      "epoch 039 | train_mse=0.40080 | val_mse=0.49479 val_rmse=0.70341 val_mae=0.52578\n",
      "epoch 040 | train_mse=0.39520 | val_mse=0.33884 val_rmse=0.58210 val_mae=0.40746\n",
      "epoch 041 | train_mse=0.39174 | val_mse=0.42253 val_rmse=0.65002 val_mae=0.45557\n",
      "epoch 042 | train_mse=0.39660 | val_mse=0.36865 val_rmse=0.60716 val_mae=0.41982\n",
      "epoch 043 | train_mse=0.39099 | val_mse=0.45747 val_rmse=0.67637 val_mae=0.50063\n",
      "epoch 044 | train_mse=0.39077 | val_mse=0.39035 val_rmse=0.62478 val_mae=0.43673\n",
      "epoch 045 | train_mse=0.39402 | val_mse=0.41304 val_rmse=0.64268 val_mae=0.44869\n",
      "epoch 046 | train_mse=0.38725 | val_mse=0.33269 val_rmse=0.57679 val_mae=0.40264\n",
      "epoch 047 | train_mse=0.38522 | val_mse=0.45528 val_rmse=0.67474 val_mae=0.47724\n",
      "epoch 048 | train_mse=0.38201 | val_mse=0.46041 val_rmse=0.67854 val_mae=0.49042\n",
      "epoch 049 | train_mse=0.38215 | val_mse=0.44469 val_rmse=0.66685 val_mae=0.47762\n",
      "epoch 050 | train_mse=0.38410 | val_mse=0.46575 val_rmse=0.68246 val_mae=0.49173\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    set_seed(42)\n",
    "    device = get_device()\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    train_loader, val_loader, in_dim = get_california_housing_loaders(\n",
    "        batch_size=128,\n",
    "        val_ratio=0.2,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Model configuration: change one knob at a time to study effects\n",
    "    model = MLPRegressor(\n",
    "        in_dim=in_dim,\n",
    "        hidden_dims=(128, 64),\n",
    "        activation=\"tanh\",     # try: \"tanh\", \"sigmoid\"\n",
    "        use_batchnorm=True,    # try: False\n",
    "        dropout_p=0.1,         # try: 0.0, 0.2\n",
    "    )\n",
    "\n",
    "    train_regression(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        optimizer_name=\"adam\",  # try: \"sgd\", \"rmsprop\", \"adam\"\n",
    "        lr=3e-4,\n",
    "        weight_decay=1e-4,      # L2\n",
    "        l1_lambda=0.0,          # optional L1, start tiny: 1e-7 or 1e-6\n",
    "        epochs=50,\n",
    "        grad_clip=None\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
