{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdb7940",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;\n",
    "        color: #cdd6f4;\n",
    "        border-left: 6px solid #89b4fa;\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "    .note-box strong { color: #f9e2af; font-weight: 600; }\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "    }\n",
    "    .note-box ul { padding-left: 20px; margin: 10px 0; }\n",
    "    .note-box li { margin-bottom: 8px; }\n",
    "</style>\n",
    "\n",
    "<div class=\"note-box\">\n",
    "    <h2>5. The Titans of Tabular Data</h2>\n",
    "    <p>\n",
    "        In the previous notebook, we built a Gradient Booster from scratch. It was powerful, but slow.\n",
    "    </p>\n",
    "    <p>\n",
    "        In the real world (and on Kaggle), \"Vanilla\" Gradient Boosting isn't enough. We need speed, efficiency, and the ability to handle messy data. Enter the <strong>Modern Titans</strong>:\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li><strong>XGBoost (eXtreme Gradient Boosting):</strong> The library that started the revolution. Famous for its speed and regularization.</li>\n",
    "        <li><strong>LightGBM (Microsoft):</strong> Built for massive datasets. It grows trees differently (\"Leaf-wise\") to be incredibly fast.</li>\n",
    "        <li><strong>CatBoost (Yandex):</strong> The king of <strong>Cat</strong>egorical data. It handles text labels (like \"Red\", \"Blue\") natively without needing complex preprocessing.</li>\n",
    "    </ul>\n",
    "    <p>\n",
    "        Today, we will pit them against each other in a <strong>Benchmark Race</strong>.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be587648",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;\n",
    "        color: #cdd6f4;\n",
    "        border-left: 6px solid #89b4fa;\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "    .note-box strong { color: #f9e2af; font-weight: 600; }\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "    }\n",
    "    .note-box ul { padding-left: 20px; margin: 10px 0; }\n",
    "    .note-box li { margin-bottom: 8px; }\n",
    "</style>\n",
    "\n",
    "<div class=\"note-box\">\n",
    "    <h2>The Contenders: How they differ</h2>\n",
    "    \n",
    "<h3>1. XGBoost (The Veteran)</h3>\n",
    "    <p>\n",
    "        Before 2016, this won almost every Kaggle competition.\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li><strong>Innovation:</strong> It added <strong>Regularization (L1 & L2)</strong> directly into the loss function (like Ridge/Lasso regression). This makes it harder to overfit than standard GBM.</li>\n",
    "        <li><strong>Growth:</strong> Level-wise. It builds the tree layer-by-layer (balanced).</li>\n",
    "    </ul>\n",
    "\n",
    "<h3>2. LightGBM (The Speedster)</h3>\n",
    "    <p>\n",
    "        When data got too big for XGBoost, Microsoft created LightGBM.\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li><strong>Innovation:</strong> <strong>Leaf-wise Growth</strong>. Instead of growing a balanced tree, it greedily hunts for the <em>single leaf</em> with the highest error and splits it. This results in deep, asymmetrical trees that learn faster.</li>\n",
    "        <li><strong>Warning:</strong> Can overfit on small datasets!</li>\n",
    "    </ul>\n",
    "\n",
    "<h3>3. CatBoost (The Specialist)</h3>\n",
    "    <p>\n",
    "        Handling categories (e.g., City names) is painful. You usually have to use \"One-Hot Encoding\", which creates huge, sparse matrices.\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li><strong>Innovation:</strong> It handles categories natively using a technique called <strong>Ordered Target Statistics</strong>. You just tell it <em>\"Column 5 is a category\"</em> and it does the math for you.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2886d7",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;\n",
    "        color: #cdd6f4;\n",
    "        border-left: 6px solid #89b4fa;\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "    .note-box strong { color: #f9e2af; font-weight: 600; }\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "    }\n",
    "    .note-box ul { padding-left: 20px; margin: 10px 0; }\n",
    "    .note-box li { margin-bottom: 8px; }\n",
    "</style>\n",
    "<div class=\"note-box\">\n",
    "    <h2>1. The Setup: Creating a \"Churn\" Dataset</h2>\n",
    "    <p>\n",
    "        To make this a fair fight, we need a dataset with <strong>Categorical Features</strong>. Most algorithms choke on text data, requiring us to turn words into numbers manually.\n",
    "    </p>\n",
    "    <p>\n",
    "        We will generate 50,000 samples of \"Customer Data\" including:\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li><strong>Numeric:</strong> Age, Income, Usage Minutes.</li>\n",
    "        <li><strong>Categorical:</strong> City (e.g., \"New York\"), Plan Type (\"Gold\", \"Silver\").</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0344eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (50000, 7)\n",
      "   Age        Income  Usage_Minutes         City      Plan  Contract_Years  \\\n",
      "0   56  73728.216871     333.832639        Miami  Platinum               2   \n",
      "1   69  44864.287170     390.254771        Miami      Gold               2   \n",
      "2   46  48216.265228     453.385153  Los Angeles  Platinum               2   \n",
      "3   32  30220.161362     176.486308     New York      Gold               1   \n",
      "4   60  47092.172656     348.357217      Houston     Basic               2   \n",
      "\n",
      "   Churn  \n",
      "0      0  \n",
      "1      0  \n",
      "2      1  \n",
      "3      0  \n",
      "4      1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 1. Generate Synthetic Data\n",
    "# We create a dataset with mixed types to test CatBoost's superpower\n",
    "np.random.seed(42)\n",
    "n_samples = 50_000\n",
    "\n",
    "data = {\n",
    "    'Age': np.random.randint(18, 70, n_samples),\n",
    "    'Income': np.random.normal(50000, 15000, n_samples),\n",
    "    'Usage_Minutes': np.random.normal(300, 100, n_samples),\n",
    "    'City': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Miami'], n_samples),\n",
    "    'Plan': np.random.choice(['Basic', 'Silver', 'Gold', 'Platinum'], n_samples),\n",
    "    'Contract_Years': np.random.choice([1, 2], n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a Target variable (Churn) based on rules + noise\n",
    "# Logic: Low income + Basic plan + High usage = High Churn Probability\n",
    "churn_prob = (\n",
    "    (df['Income'] < 40000).astype(int) * 0.3 + \n",
    "    (df['Plan'] == 'Basic').astype(int) * 0.4 + \n",
    "    (df['Usage_Minutes'] > 400).astype(int) * 0.5 +\n",
    "    np.random.normal(0, 0.2, n_samples)\n",
    ")\n",
    "df['Churn'] = (churn_prob > 0.5).astype(int)\n",
    "\n",
    "# 2. Preprocessing\n",
    "# XGBoost & LightGBM need numbers, not strings (historically). \n",
    "# CatBoost takes strings directly.\n",
    "# For fairness, we create a copy with \"Ordinal Encoding\" for XGB/LGBM\n",
    "df_numeric = df.copy()\n",
    "df_numeric['City'] = df_numeric['City'].astype('category').cat.codes\n",
    "df_numeric['Plan'] = df_numeric['Plan'].astype('category').cat.codes\n",
    "\n",
    "# Split\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "X_num = df_numeric.drop('Churn', axis=1) # Version for XGB/LGBM\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(X_num, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af50c16",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Main container style */\n",
    "    .note-box {\n",
    "        background-color: #1e1e2e;\n",
    "        color: #cdd6f4;\n",
    "        border-left: 6px solid #89b4fa;\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        margin: 20px 0;\n",
    "        font-family: system-ui, -apple-system, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);\n",
    "        box-sizing: border-box;\n",
    "        max-width: 100%;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "    .note-box h2 {\n",
    "        color: #89b4fa;\n",
    "        margin-top: 0;\n",
    "        margin-bottom: 15px;\n",
    "        font-size: 1.6rem;\n",
    "        font-weight: 600;\n",
    "        border-bottom: 1px solid #45475a;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "    .note-box strong { color: #f9e2af; font-weight: 600; }\n",
    "    .note-box .code-inline {\n",
    "        background-color: #313244;\n",
    "        color: #f38ba8;\n",
    "        padding: 2px 6px;\n",
    "        border-radius: 4px;\n",
    "        font-family: 'Menlo', 'Consolas', monospace;\n",
    "        font-size: 0.9em;\n",
    "        border: 1px solid #45475a;\n",
    "    }\n",
    "    .note-box ul { padding-left: 20px; margin: 10px 0; }\n",
    "    .note-box li { margin-bottom: 8px; }\n",
    "</style>\n",
    "<div class=\"note-box\">\n",
    "    <h2>2. The Benchmark Race</h2>\n",
    "    <p>\n",
    "        We will train all three models on the exact same data. We track two metrics:\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li><strong>Training Time:</strong> How long does it take to learn?</li>\n",
    "        <li><strong>Accuracy:</strong> How smart is the model?</li>\n",
    "    </ul>\n",
    "    <p>\n",
    "        <em>Note: We are using default hyperparameters to see \"out-of-the-box\" performance.</em>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a216d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "Training LightGBM...\n",
      "Training CatBoost...\n",
      "\n",
      "--- Race Finished! ---\n",
      "      Model      Time  Accuracy\n",
      "0   XGBoost  0.650963    0.8637\n",
      "1  LightGBM  2.072699    0.8608\n",
      "2  CatBoost  3.219243    0.8634\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {'Model': [], 'Time': [], 'Accuracy': []}\n",
    "\n",
    "# --- 1. XGBoost ---\n",
    "# Uses the numeric dataset\n",
    "print(\"Training XGBoost...\")\n",
    "start = time.time()\n",
    "model_xgb = xgb.XGBClassifier(n_estimators=500, learning_rate=0.05, n_jobs=-1, random_state=42)\n",
    "model_xgb.fit(X_train_num, y_train_num)\n",
    "end = time.time()\n",
    "\n",
    "acc_xgb = accuracy_score(y_test_num, model_xgb.predict(X_test_num))\n",
    "results['Model'].append('XGBoost')\n",
    "results['Time'].append(end - start)\n",
    "results['Accuracy'].append(acc_xgb)\n",
    "\n",
    "\n",
    "# --- 2. LightGBM ---\n",
    "# Uses the numeric dataset\n",
    "print(\"Training LightGBM...\")\n",
    "start = time.time()\n",
    "model_lgb = lgb.LGBMClassifier(n_estimators=500, learning_rate=0.05, n_jobs=-1, random_state=42, verbose=-1)\n",
    "model_lgb.fit(X_train_num, y_train_num)\n",
    "end = time.time()\n",
    "\n",
    "acc_lgb = accuracy_score(y_test_num, model_lgb.predict(X_test_num))\n",
    "results['Model'].append('LightGBM')\n",
    "results['Time'].append(end - start)\n",
    "results['Accuracy'].append(acc_lgb)\n",
    "\n",
    "\n",
    "# --- 3. CatBoost ---\n",
    "# Uses the ORIGINAL string dataset (X_train). We tell it which columns are categories.\n",
    "print(\"Training CatBoost...\")\n",
    "cat_features = ['City', 'Plan'] # Names of categorical columns\n",
    "\n",
    "start = time.time()\n",
    "model_cat = CatBoostClassifier(n_estimators=500, learning_rate=0.05, verbose=0, random_state=42)\n",
    "model_cat.fit(X_train, y_train, cat_features=cat_features)\n",
    "end = time.time()\n",
    "\n",
    "acc_cat = accuracy_score(y_test, model_cat.predict(X_test))\n",
    "results['Model'].append('CatBoost')\n",
    "results['Time'].append(end - start)\n",
    "results['Accuracy'].append(acc_cat)\n",
    "\n",
    "print(\"\\n--- Race Finished! ---\")\n",
    "# Create and display the results table immediately\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d01044",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Helia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
